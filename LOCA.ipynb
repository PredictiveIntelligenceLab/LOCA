{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEMoBgf5y9aw"
      },
      "source": [
        "# The LOCA method in JAX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rz5QW1dGDUwX"
      },
      "source": [
        "# How the LOCA works for one output query point:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4RLxoakzB-t"
      },
      "source": [
        "Before we get into the code, let's talk about the LOCA math in order to design an algorithm that makes the implentation in JAX vectorized, fast and  memory efficient.\n",
        "\n",
        "Let's consider the case of a LOCA as shown below:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJG6u2dLBRA3"
      },
      "source": [
        "Given $\\mathcal{X} ⊂ \\mathbb{R}^{d_x}$, $\\mathcal{Y} ⊂ \\mathbb{R}^{d_y}$ we refer to $x \\in \\mathcal{X}$ as the input and  $y \\in \\mathcal{Y}$ as the query locations. We define functions $u^l \\in \\mathcal{C}(\\mathcal{X}, \\mathbb{R}^{d_u})$ the input functions and $s^l \\in \\mathcal{C}(\\mathcal{Y}, \\mathbb{R}^{d_s})$ the output functions. \n",
        "\n",
        "Our goal is to learn an operator $\\mathcal{G}: \\mathcal{C}(\\mathcal{X}, \\mathbb{R}^{d_u}) \\to \\mathcal{C}(\\mathcal{Y}, \\mathbb{R}^{d_s})$ using pairs of input/output functions $\\{ u^l(x), s^l(y) \\}_{l=1}^N$. \n",
        "\n",
        "To do that we consider the parameterized model:\n",
        "\n",
        "$$\\mathcal{F}(u)(y) = \\sum_{i=1}^n \\varphi(y)_i \\odot v(u)_i,   \\quad \\quad (1)$$\n",
        "\n",
        "where $v$ and $\\varphi$ the approximator and decoder maps, respectively. \n",
        "\n",
        "We can also write the above as:\n",
        "\n",
        "$$\\mathcal{F}(u)(y) =  \\mathbb{E}_{\\varphi(y)}[v(u)] = \\sum_{i=1}^n \\sigma\\left(\\int_\\mathcal{Y} \\kappa(y,y') g(y')\\;dy'\\right)_i \\odot v_i(u)$$\n",
        "\n",
        "and we need to compute:\n",
        "\n",
        "$$\\varphi(y) = \\sigma\\left(\\int_\\mathcal{Y} \\kappa(y,y') g(y')\\;dy'\\right)$$\n",
        "\n",
        "where:\n",
        "\n",
        "$$ \\kappa(y,y') := \\frac{k(q_{\\theta}(y),q_{\\theta}(y'))}{\\left(\\int_\\mathcal{Y} k(q_{\\theta}(y),q_{\\theta}(z)) dz\\right)^{1/2}\\left(\\int_\\mathcal{Y} k(q_{\\theta}(y'),q_{\\theta}(z)) dz\\right)^{1/2}}.$$\n",
        "\n",
        "Therefore, $v$ network is a function $v: \\mathbb{R}^{m \\times d_u} \\to \\mathbb{R}^{n \\times d_s}$ of the input $u$ and $\\varphi$ is a function $\\varphi: \\mathbb{R}^{1 \\times d_y} \\to \\prod_{i=1}^{d_s}\\Delta^n$ of the query location $y^i_l$. For each input and query location (1) provides an output $s^i_l \\in \\mathbb{R}^{1 \\times ds}$. \n",
        "\n",
        "Now that we wrote (1) for one query point we can use the JAX library automatic vectorization properties to vectorize (1) over multiple query points and multiple dimensions. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc2mEpbCWVhZ"
      },
      "source": [
        "# Predicting flow through a porous medium\n",
        "\n",
        "Fluid flow through porous media is governed by Darcy's Law, which can be mathematically expressed by the following partial differential equation system,\n",
        "$$ \\nabla \\cdot ( u(x) \\nabla s(x)) = f(x), \\quad x \\in \\mathcal{X},$$\n",
        "subject to appropriate boundary conditions\n",
        "\n",
        "$$ s = 0   \\quad \\text{on} \\quad \\Gamma_\\mathcal{X},$$ \n",
        "$$(u(x)  \\nabla  s(x)) \\cdot n = g  \\quad \\text{ on } \\Gamma_N, $$\n",
        "where $u$ is permeability of the porous medium, and $s$ is the corresponding fluid pressure. Here we consider a domain $\\mathcal{X} = [0,1] \\times [0,1]$ with a Dirichlet boundary  $\\Gamma_D = \\{ (0,x) \\cup (1,x)\\;|\\;x_2 \\in [0,1] \\subset \\partial \\mathcal{X} \\}$, and a Neumann boundary $\\Gamma_N = \\{ (x,0) \\cup (x,1) \\;|\\;x \\in [0,1]\\subset \\partial \\mathcal{X} \\}$. \n",
        "\n",
        "For a given forcing term $f$ and set of boundary conditions, the solution operator $\\mathcal{G}$ of system maps the permeability function $u(x)$ to the fluid pressure function $s(x)$. In the notation of our model, the input and output function domains coincide, $\\mathcal{X} = \\mathcal{Y}$ with $d_x = d_y = 2$. Since in this case the solution operator is a map between scalar functions, we also have $d_u = d_s = 1$. Under this setup, our goal is to learn the solution operator $\\mathcal{G}: C(\\mathcal{X}, \\mathbb{R}) \\to C(\\mathcal{X}, \\mathbb{R})$. \n",
        "\n",
        "We set the Neumann boundary condition to be $g(x) = \\sin(5x)$, the forcing term $f(x) = 5 \\exp( - ((x_1-0.5)^2 + (x_2-0.5)^2))$, and sample the permeability function $u(x)$ from a Gaussian measure, as $u(x) = \\exp(u_0 \\cos(x))$ with $u_0 \\sim \\mathcal{N}(0, 7^{3/2}(- \\Delta + 49 I)^{-1.5}$. The training and testing data sets are constructed by sampling the initial condition along a $N_x \\times N_y$ grid and solving the forward problem with the Finite Element library, Fenics. This gives us access to $N_x \\times N_y$ solution values to use for training different operator learning models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzOMRlvtDbAx"
      },
      "source": [
        "# Importing the necessary libraries for implementing the LOCA method:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GzAfdTWBRMN"
      },
      "source": [
        "Let's first import the libraries that we are going to use for implementing the LOCA method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ejpWakv3Eyw",
        "outputId": "1e47138e-9168-4f84-979d-ec930dd9e120"
      },
      "outputs": [],
      "source": [
        "from jax.example_libraries.stax import Dense, Gelu\n",
        "from jax.example_libraries import stax\n",
        "import os\n",
        "import timeit\n",
        "import jax\n",
        "from jax.example_libraries import optimizers\n",
        "from jax.flatten_util import ravel_pytree\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "from jax.numpy.linalg import norm\n",
        "from jax import random, grad, vmap, jit\n",
        "from functools import partial \n",
        "from torch.utils import data\n",
        "from tqdm import trange\n",
        "import itertools\n",
        "from kymatio.numpy import Scattering2D\n",
        "\n",
        "from numpy.polynomial.legendre import leggauss\n",
        "\n",
        "def get_freer_gpu():\n",
        "    os.system('nvidia-smi -q -d Memory |grep -A4 GPU|grep Used >tmp')\n",
        "    memory_available = [int(x.split()[2]) for x in open('tmp', 'r').readlines()]\n",
        "    return str(np.argmin(memory_available))\n",
        "os.environ['CUDA_VISIBLE_DEVICES']= get_freer_gpu()\n",
        "os.environ['XLA_PYTHON_CLIENT_PREALLOCATE']=\"False\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKIt-ZnVDiEe"
      },
      "source": [
        "# Randomly choosing output labels for training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3i28_DjmUba2"
      },
      "source": [
        "In contrast to the Image2image regression, where for each of the N input/output function pairs, $(u_i, s_i)$ we need the full resolution of the output as labels, in DeepONet we can randomly subsample the output function queries to use as labels for our input data. We will consider $m$ discrete measurements of each input function at fixed locations, $(u^i(x^i_1), . . . , u^i(x^i_m))$, and $M$ available discrete measurements of each output function $(s^i(y^i_1), . . . , si(y^i_M ))$, with the query locations $ \\{ y^i_l \\}^M_{l=1}$ potentially varying over the data set. Out of the $M$ available measurement points $\\{ y^i_l \\}^M_{l=1}$ for each output function $s^i$, we consider the effect of taking only $P$ of these points for each input/output pair. \n",
        "\n",
        "\n",
        "![Part 4.jpg](data:image/jpeg;base64,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)\n",
        "\n",
        "\n",
        "The LOCA implementation we provide assumes a fixed number of output measurements $P$, which is not as general.\n",
        "\n",
        "\n",
        "For sampling the $P$ labels from the output domain we employ the function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_ztfEyUt3Ngk"
      },
      "outputs": [],
      "source": [
        "def output_construction(s,Y,P=100,ds=1, dy=2, N=1000,Nx=100,Ny=100):\n",
        "    s = s.reshape(Nx,Ny, ds)\n",
        "    Y = Y.reshape(Nx,Ny, dy)\n",
        "    x = np.random.randint(Nx, size=P)\n",
        "    y = np.random.randint(Ny, size=P)\n",
        "    Y_all = Y[x][range(P), y, :]\n",
        "    s_all = s[x][range(P), y, :]\n",
        "    return s_all, Y_all"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bXWUq83D0ry"
      },
      "source": [
        "# Handling batches "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DU_D_q2Dh1dq"
      },
      "source": [
        "For fetching mini-batches during training, we will define a `DataGenerator` class, which performs two actions:\n",
        "\n",
        "* Creates a random key each time that it is called,\n",
        "* Randomly chooses batches of realizations from the data-set and returns a tuple containing the argumetns of the forward pass $\\mathcal{F}(u^i)(y^i)$ and $s^i$ target functions for comparing with the prediction in the loss function. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "F8-TwcUA3QPX"
      },
      "outputs": [],
      "source": [
        "class DataGenerator(data.Dataset):\n",
        "    def __init__(self, inputsxu, y, s, z, w,\n",
        "                 batch_size=100, rng_key=random.PRNGKey(1234)):\n",
        "        'Initialization'\n",
        "        self.inputsxu  = inputsxu\n",
        "        self.y = y\n",
        "        self.s = s\n",
        "        self.z = z\n",
        "        self.w = w\n",
        "        \n",
        "        self.N = inputsxu.shape[0]\n",
        "        self.batch_size = batch_size\n",
        "        self.key = rng_key\n",
        "\n",
        "    # @partial(jit, static_argnums=(0,))\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        self.key, subkey = random.split(self.key)\n",
        "        inputs,outputs = self.__data_generation(subkey)\n",
        "        return inputs, outputs\n",
        "\n",
        "    @partial(jit, static_argnums=(0,))\n",
        "    def __data_generation(self, key):\n",
        "        'Generates data containing batch_size samples'\n",
        "        idx = random.choice(key, self.N, (self.batch_size,), replace=False)\n",
        "        s = self.s[idx,:,:]\n",
        "        inputsxu  = self.inputsxu[idx,:,:]\n",
        "        y = self.y[idx,:,:]\n",
        "        z = self.z[idx,:,:]\n",
        "        w = self.w[idx,:,:]\n",
        "        inputs = (inputsxu, y, z, w)\n",
        "        return inputs, s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtmYMxvrD3yM"
      },
      "source": [
        "# Harmonic feature expansion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvmrZANVi6H9"
      },
      "source": [
        "Lu _et. al._ proposed in their paper _\"A comprehensive and fair comparison of two neural operators (with practical extensions) based on fair data.\"_ a technique called Harmonic Feature Expansion defined as:\n",
        "\n",
        "$$(cos(2^0 \\pi y), sin(2^0 \\pi y), cos(2^1 \\pi y), sin(2^1 \\pi y),..., cos(2^H \\pi y),sin(2^H \\pi y))$$\n",
        "\n",
        "which is then concatenated to the query locations. We perform the same augmentation with the input function samples. This process is performed for each dimension separately: \n",
        "$$e(y^i, 2j + (i-1)H  = cos(2^i \\pi y^i) \\\\ \n",
        "e(y^i, 2j + 1+ (i-1)H = sin(2^i \\pi y^i) $$\n",
        "\n",
        "where $H$ the number of expansion coefficients, $j = 1,...,H/2$, $y^i$ the query coordinates in different spatial dimensions and $i = 1,...,d_y$. \n",
        "\n",
        "For this purpose, we create a vectorized function in JAX to apply the above efficiently to the whole dataset. \n",
        "\n",
        "The Harmonic Feature Expansion or other types of encodings, i.e. positional encodings in the Transformers literature, provide an intuitive way to include indirect positional information about the functions that are feeded to a neural network. This has been proven to be very effective in the Transformers literature and it is widely used. \n",
        "\n",
        "In learning for physics, positional encodings provide an intuitive way to handle different structures that might be present in a dataset that comes from some physical system, like periodic boundary conditions, oscillations, high frequencies, all at once. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JfL_53Cm3TOr"
      },
      "outputs": [],
      "source": [
        "class HarmonicFeatureExpansionY:\n",
        "    def __init__(self, Y, d_model, max_len = 100, H=20):\n",
        "        self.d_model = int(np.ceil(d_model/4)*2)\n",
        "        self.Y = Y\n",
        "        self.max_len = max_len\n",
        "        self.H = H\n",
        "\n",
        "    @partial(jit, static_argnums=(0,))\n",
        "    def forward(self, x):\n",
        "        pex = np.zeros((x.shape[0], self.max_len, self.H))\n",
        "        pey = np.zeros((x.shape[0], self.max_len, self.H))\n",
        "        T = jnp.take(self.Y, 0, axis=2)[:,:,None]\n",
        "        X = jnp.take(self.Y, 1, axis=2)[:,:,None]\n",
        "        positionT = jnp.tile(T,(1,1,self.H))\n",
        "        positionX = jnp.tile(X,(1,1,self.H))\n",
        "        div_term = 2**jnp.arange(0,int(self.H/2),1)*jnp.pi\n",
        "        pex = jax.ops.index_update(pex, jax.ops.index[:,:,0::2], jnp.cos(positionT[:,:,0::2] * div_term))\n",
        "        pex = jax.ops.index_update(pex, jax.ops.index[:,:,1::2], jnp.sin(positionT[:,:,1::2] * div_term))\n",
        "        pey = jax.ops.index_update(pey, jax.ops.index[:,:,0::2], jnp.cos(positionX[:,:,0::2] * div_term))\n",
        "        pey = jax.ops.index_update(pey, jax.ops.index[:,:,1::2], jnp.sin(positionX[:,:,1::2] * div_term))\n",
        "        pos_embedding =  jnp.concatenate((pex,pey),axis=-1) # [[x,pex],\n",
        "                                                            # [y,pey]]\n",
        "        x =  jnp.concatenate([x, pos_embedding], -1)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Scattering Transform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The wavelet scattering transform is performed on the input functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def scatteringTransform(sig, training_batch_size = 100):\n",
        "    scattering = Scattering2D(J=1, L=3, max_order=2, shape=(32, 32))\n",
        "    cwtmatr = np.zeros((training_batch_size, 768, 1))\n",
        "    sig = np.array(sig)\n",
        "    for i in range(0,training_batch_size):\n",
        "        scatteringCoeffs = scattering(sig[i,:,:].reshape(32,32))\n",
        "        cwtmatr[i,:,:] = scatteringCoeffs[:3,:,:].flatten()[:,None]\n",
        "    return cwtmatr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Auxiliary functions for kernel computation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we define some auxiliary functions to compute the square euclidean distance between two vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pairwise_distances(dist,**arg):\n",
        "    return jit(vmap(vmap(partial(dist,**arg),in_axes=(None,0)),in_axes=(0,None)))\n",
        "\n",
        "def euclid_distance(x,y):\n",
        "    XX=jnp.dot(x,x)\n",
        "    YY=jnp.dot(y,y)\n",
        "    XY=jnp.dot(x,y)\n",
        "    return XX+YY-2*XY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nLInB6gD6h1"
      },
      "source": [
        "# Loss Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svzpXw__mREB"
      },
      "source": [
        "For training the model, we consider a relative $\\mathcal{L}_2$ error loss: \n",
        "$$ \\mathcal{L}(\\theta) = \\frac{1}{N} \\sum_{i=1}^N \\sum_{j=1}^P \\frac{\\| s^i(y_j^i) - \\mathcal{G}(u^i)(y_j^i) \\|^2_2}{\\| s^i(y_j^i) \\|^2_2}$$\n",
        "\n",
        "as in the Fourier Neural Operators, which we will see in the next tutorial. The $\\mathcal{L}_2$ loss function weights each component differently depending on the norm of the target function sample. \n",
        "\n",
        "\n",
        "One of the reason we employ this loss function is to to avoid biasing the model towards over-fitting to functions with larger magnitudes. Moreover, there has been a success of methods that consider adaptive weights to the loss function and this is a intuitive way to choose the weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zsVBvtr7d6ee"
      },
      "outputs": [],
      "source": [
        "class LpLoss(object):\n",
        "    def __init__(self, d=2, p=2):\n",
        "        super(LpLoss, self).__init__()\n",
        "        self.d = d\n",
        "        self.p = p\n",
        "\n",
        "    def rel(self, x, y):\n",
        "        num_examples = x.shape[0]\n",
        "        diff_norms = jnp.linalg.norm(y.reshape(num_examples,-1) - x.reshape(num_examples,-1), self.p, 1)\n",
        "        y_norms = jnp.linalg.norm(y.reshape(num_examples,-1), self.p, 1)\n",
        "        return jnp.mean(diff_norms/y_norms)\n",
        "\n",
        "    def __call__(self, x, y):\n",
        "        return self.rel(x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Another choice of loss function is the mean squared error loss used throught the examples in the manuscript:\n",
        "\n",
        "$$ \\mathcal{L}(\\theta) = \\frac{1}{NP} \\sum_{i=1}^N \\sum_{j=1}^P \\big ( s^i(y_j^i) - \\mathcal{G}(u^i)(y_j^i)  \\big ) ^2 $$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def loss(self, params, batch):\n",
        "    inputs, outputs = batch\n",
        "    y_pred = self.OKSA_net(params,inputs)\n",
        "    loss = np.mean((outputs.flatten() - y_pred.flatten())**2)\n",
        "    return loss    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIKS1_jMD83c"
      },
      "source": [
        "# LOCA model implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkGEycZJoODR"
      },
      "source": [
        "At this point we will define a class which we will call LOCA and will contain the LOCA model definition, forward pass, the optimizer and the training loop. \n",
        "\n",
        "We will explain the important parts of this class:\n",
        "\n",
        "Following the `stax` library syntax we define two pure function, one for the branch and one for the trunk network using the network initialization funtion `init_NN` which returns one apply and one initialization function. We define the input shapes as `(-1, q_layers[0])`,`(-1, v_layers[0])` and `(-1, g_layers[0])` to indicate that we want the function to be vectorized in every dimension except for the last. Remember $v$ has shape $N_{samples} \\times 1 \\times d_u*m$ and $\\varphi$ has shape $N_{samples} \\times P \\times d_y$.\n",
        "\n",
        "```\n",
        "self.q_init, self.q_apply = self.init_NN(q_layers, activation=Gelu)\n",
        "self.in_shape = (-1, q_layers[0])\n",
        "self.out_shape, q_params = self.q_init(random.PRNGKey(10000), self.in_shape)\n",
        "\n",
        "self.v_init, self.v_apply = self.init_NN(v_layers, activation=Gelu)\n",
        "self.in_shape = (-1, v_layers[0])\n",
        "self.out_shape, v_params = self.v_init(random.PRNGKey(10000), self.in_shape)\n",
        "\n",
        "self.g_init, self.g_apply = self.init_NN(g_layers, activation=Gelu)\n",
        "self.in_shape = (-1, g_layers[0])\n",
        "self.out_shape, g_params = self.g_init(random.PRNGKey(10000), self.in_shape)\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "We discussed on the start of the tutorial how the LOCA method works for one query coordinate $y^i_l$. The forward pass presented below follows is exactly this process vectorized to handled $P$ points at the same time. \n",
        "\n",
        "```\n",
        "def LOCA_net(self, params, inputs, ds=1):\n",
        "      # Get model parameters\n",
        "      beta, gamma, q_params, g_params, v_params = params\n",
        "      # Get inputs from data generator\n",
        "      u, y, z, w = inputs\n",
        "      # Get q(y) and q(z)\n",
        "      inputsy  = self.q_apply(q_params,y)\n",
        "      inputsz  = self.q_apply(q_params,z)\n",
        "\n",
        "      # Get k = -\\beta \\exp( - gamma ||q(z) - q(z)||^2)\n",
        "      K =  self.RBF(z, z, gamma, beta)\n",
        "      Kzz =  jnp.sqrt(self.jac_det*jnp.einsum(\"ijk,ikl->ijl\",K,w))\n",
        "      # Compute \\sqrt(\\int k(z, z) dz) for normalizing the kernel\n",
        "      Kzz =  jnp.sqrt(self.jac_det*jnp.einsum(\"ijk,ikl->ijl\",K,w))\n",
        "\n",
        "      # Get k = -\\beta \\exp( - gamma ||q(y) - q(z)||^2)\n",
        "      # Compute \\sqrt(\\int k(y, z) dz) for normalizing the kernel\n",
        "      K =  self.RBF(y, z, gamma, beta)\n",
        "      Kyz =  jnp.sqrt(self.jac_det*jnp.einsum(\"ijk,ikl->ijl\",K,w))\n",
        "      mean_K = jnp.matmul(Kyz, jnp.swapaxes(Kzz,1,2))\n",
        "      # Normalize the kernel\n",
        "      K = jnp.divide(K,mean_K)\n",
        "\n",
        "      # Compute g(z)\n",
        "      g  = self.g_apply(g_params, inputsz)\n",
        "      # Compute \\tilde{g} = \\int K(y,z) g(z) dz\n",
        "      g = jnp.einsum(\"ijk,ikl,ikm->ijml\",K,g,w)\n",
        "      # Compute \\varphi(y)\n",
        "      g = jax.nn.softmax(g.reshape(g.shape[0],g.shape[1], ds, int(g.shape[-1]/ds)), axis=-1)\n",
        "\n",
        "      # Compute v = f \\circ \\mathcal{D}(u)\n",
        "      v = self.v_apply(v_params, u.reshape(u.shape[0],1,u.shape[1]*u.shape[2]))\n",
        "      v = v.reshape(v.shape[0],int(v.shape[2]/ds),ds)\n",
        "      # Compute the expectation \\mathbb{E}_{\\varphi(y)}[v(u)]\n",
        "      Guy = jnp.einsum(\"ijkl,ilk->ijk\", g,v)\n",
        "      return Guy\n",
        "```\n",
        "\n",
        "The way the other functions work is self explanatory, therefore we will not go into details.\n",
        "\n",
        "The whole `LOCA` model class is presented below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4pLU6lvQsZhW"
      },
      "outputs": [],
      "source": [
        "class LOCA:\n",
        "    def __init__(self, q_layers, g_layers, v_layers , m=100, P=100, jac_det=None):    \n",
        "        # Network initialization and evaluation functions\n",
        "        self.q_init, self.q_apply = self.init_NN(q_layers, activation=Gelu)\n",
        "        self.in_shape = (-1, q_layers[0])\n",
        "        self.out_shape, q_params = self.q_init(random.PRNGKey(10000), self.in_shape)\n",
        "\n",
        "        self.v_init, self.v_apply = self.init_NN(v_layers, activation=Gelu)\n",
        "        self.in_shape = (-1, v_layers[0])\n",
        "        self.out_shape, v_params = self.v_init(random.PRNGKey(10000), self.in_shape)\n",
        "        self.v_apply = jit(self.v_apply)\n",
        "\n",
        "        self.g_init, self.g_apply = self.init_NN(g_layers, activation=Gelu)\n",
        "        self.in_shape = (-1, g_layers[0])\n",
        "        self.out_shape, g_params = self.g_init(random.PRNGKey(10000), self.in_shape)\n",
        "        self.g_apply = jit(self.g_apply)\n",
        "\n",
        "        # RBF kernel parameters\n",
        "        beta = [10.]\n",
        "        gamma = [0.2]\n",
        "\n",
        "        # Model parameters\n",
        "        params = (beta, gamma,q_params, g_params, v_params)\n",
        "\n",
        "        self.jac_det = jac_det\n",
        "\n",
        "        # Use optimizers to set optimizer initialization and update functions\n",
        "        self.opt_init,self.opt_update,self.get_params = optimizers.adam(optimizers.exponential_decay(1e-3, \n",
        "                                                                      decay_steps=100, \n",
        "                                                                      decay_rate=0.99))\n",
        "        self.opt_state = self.opt_init(params)\n",
        "        # Logger\n",
        "        self.itercount = itertools.count()\n",
        "        self.loss_log = []\n",
        "\n",
        "        self.grads = []\n",
        "\n",
        "        self.vdistance_function = vmap(pairwise_distances(euclid_distance))\n",
        "\n",
        "    def init_NN(self, Q, activation=Gelu):\n",
        "        layers = []\n",
        "        num_layers = len(Q)\n",
        "        if num_layers < 2:\n",
        "            net_init, net_apply = stax.serial()\n",
        "        else:\n",
        "            for i in range(0, num_layers-2):\n",
        "                layers.append(Dense(Q[i+1]))\n",
        "                layers.append(activation)\n",
        "            layers.append(Dense(Q[-1]))\n",
        "            net_init, net_apply = stax.serial(*layers)\n",
        "        return net_init, net_apply\n",
        "\n",
        "\n",
        "    @partial(jax.jit, static_argnums=0)\n",
        "    def RBF(self, X, Y, gamma, beta):\n",
        "        d = self.vdistance_function(X, Y)\n",
        "        return beta[0]*jnp.exp(-gamma[0]*d) \n",
        "\n",
        "    @partial(jax.jit, static_argnums=0)\n",
        "    def Mattern_32(self, X, Y, gamma, beta):\n",
        "        d = self.vdistance_function(X, Y)\n",
        "        return (1 + (jnp.sqrt(3)*gamma[0])*d)*beta[0]*jnp.exp(-(jnp.sqrt(3)*gamma[0])*d)\n",
        "\n",
        "    @partial(jax.jit, static_argnums=0)\n",
        "    def Mattern_52(self, X, Y, gamma, beta):\n",
        "        d = self.vdistance_function(X, Y)\n",
        "        return (1 + (jnp.sqrt(5)*gamma[0])*d + (5/3*gamma[0])*d**2)*beta[0]*jnp.exp(-(jnp.sqrt(5)*gamma[0])*d)\n",
        "\n",
        "    @partial(jax.jit, static_argnums=0)\n",
        "    def periodic(self, X, Y, gamma, beta):\n",
        "        d = self.vdistance_function(X, Y)\n",
        "        return jnp.exp(-2.0*jnp.sin(jnp.pi*d*beta[0])*gamma[0]**2)\n",
        "\n",
        "    @partial(jax.jit, static_argnums=0)\n",
        "    def RQK(self, X, Y, gamma, beta):\n",
        "        d = self.vdistance_function(X, Y)\n",
        "        return beta[0]*(1 + (1./3.)*gamma[0]*d)**(gamma[0]) \n",
        "\n",
        "    def LOCA_net(self, params, inputs, ds=1):\n",
        "        # Get model parameters\n",
        "        beta, gamma, q_params, g_params, v_params = params\n",
        "        # Get inputs from data generator\n",
        "        u, y, z, w = inputs\n",
        "        # Get q(y) and q(z)\n",
        "        inputsy  = self.q_apply(q_params,y)\n",
        "        inputsz  = self.q_apply(q_params,z)\n",
        "\n",
        "        # Get k = -\\beta \\exp( - gamma ||q(z) - q(z)||^2)\n",
        "        K =  self.RBF(z, z, gamma, beta)\n",
        "        Kzz =  jnp.sqrt(self.jac_det*jnp.einsum(\"ijk,ikl->ijl\",K,w))\n",
        "        # Compute \\sqrt(\\int k(z, z) dz) for normalizing the kernel\n",
        "        Kzz =  jnp.sqrt(self.jac_det*jnp.einsum(\"ijk,ikl->ijl\",K,w))\n",
        "\n",
        "        # Get k = -\\beta \\exp( - gamma ||q(y) - q(z)||^2)\n",
        "        # Compute \\sqrt(\\int k(y, z) dz) for normalizing the kernel\n",
        "        K =  self.RBF(y, z, gamma, beta)\n",
        "        Kyz =  jnp.sqrt(self.jac_det*jnp.einsum(\"ijk,ikl->ijl\",K,w))\n",
        "        mean_K = jnp.matmul(Kyz, jnp.swapaxes(Kzz,1,2))\n",
        "        # Normalize the kernel\n",
        "        K = jnp.divide(K,mean_K)\n",
        "\n",
        "        # Compute g(z)\n",
        "        g  = self.g_apply(g_params, inputsz)\n",
        "        # Compute \\tilde{g} = \\int K(y,z) g(z) dz\n",
        "        g = jnp.einsum(\"ijk,ikl,ikm->ijml\",K,g,w)\n",
        "        # Compute \\varphi(y)\n",
        "        g = jax.nn.softmax(g.reshape(g.shape[0],g.shape[1], ds, int(g.shape[-1]/ds)), axis=-1)\n",
        "\n",
        "        # Compute v = f \\circ \\mathcal{D}(u)\n",
        "        v = self.v_apply(v_params, u.reshape(u.shape[0],1,u.shape[1]*u.shape[2]))\n",
        "        v = v.reshape(v.shape[0],int(v.shape[2]/ds),ds)\n",
        "        # Compute the expectation \\mathbb{E}_{\\varphi(y)}[v(u)]\n",
        "        Guy = jnp.einsum(\"ijkl,ilk->ijk\", g,v)\n",
        "        return Guy\n",
        "\n",
        "\n",
        "    @partial(jax.jit, static_argnums=0)\n",
        "    def loss(self, params, batch):\n",
        "        inputs, outputs = batch\n",
        "        y_pred = self.LOCA_net(params,inputs)\n",
        "        loss = np.mean((outputs.flatten() - y_pred.flatten())**2)\n",
        "        return loss    \n",
        "\n",
        "    @partial(jax.jit, static_argnums=0)\n",
        "    def lossT(self, params, batch):\n",
        "        inputs, outputs = batch\n",
        "        y_pred = self.LOCA_net(params,inputs)\n",
        "        loss = np.mean((outputs.flatten() - y_pred.flatten())**2)\n",
        "        return loss    \n",
        "    \n",
        "    @partial(jax.jit, static_argnums=0)\n",
        "    def L2errorT(self, params, batch):\n",
        "        inputs, y = batch\n",
        "        y_pred = self.LOCA_net(params,inputs)\n",
        "        return norm(y_pred.flatten() - y.flatten(), 2)/norm(y_pred.flatten(),2)\n",
        "\n",
        "    @partial(jax.jit, static_argnums=0)\n",
        "    def L2error(self, params, batch):\n",
        "        inputs, y = batch\n",
        "        y_pred = self.LOCA_net(params,inputs)\n",
        "        return norm(y_pred.flatten() - y.flatten(), 2)/norm(y_pred.flatten(),2)\n",
        "    \n",
        "    @partial(jit, static_argnums=(0,))\n",
        "    def step(self, i, opt_state, batch):\n",
        "        params = self.get_params(opt_state)\n",
        "        g = grad(self.loss)(params, batch)\n",
        "        return self.opt_update(i, g, opt_state), g\n",
        "\n",
        "    def train(self, train_dataset, test_dataset, nIter = 10000):\n",
        "        train_data = iter(train_dataset)\n",
        "        test_data  = iter(test_dataset)\n",
        "\n",
        "        pbar = trange(nIter)\n",
        "        for it in pbar:\n",
        "            train_batch = next(train_data)\n",
        "            test_batch  = next(test_data)\n",
        "\n",
        "            self.opt_state, g = self.step(next(self.itercount), self.opt_state, train_batch)\n",
        "\n",
        "            \n",
        "            if it % 100 == 0:\n",
        "                params = self.get_params(self.opt_state)\n",
        "                self.grads.append(g)\n",
        "\n",
        "                loss_train = self.loss(params, train_batch)\n",
        "                loss_test  = self.lossT(params, test_batch)\n",
        "\n",
        "                errorTrain = self.L2error(params, train_batch)\n",
        "                errorTest  = self.L2errorT(params, test_batch)\n",
        "\n",
        "                self.loss_log.append(loss_train)\n",
        "\n",
        "                pbar.set_postfix({'Training loss': loss_train, \n",
        "                                  'Testing loss' : loss_test,\n",
        "                                  'Test error':    errorTest,\n",
        "                                  'Train error':   errorTrain})\n",
        "\n",
        "    @partial(jit, static_argnums=(0,))\n",
        "    def predict(self, params, inputs):\n",
        "        s_pred = self.LOCA_net(params,inputs)\n",
        "        return s_pred\n",
        "\n",
        "    @partial(jit, static_argnums=(0,))\n",
        "    def predictT(self, params, inputs):\n",
        "        s_pred = self.LOCA_net(params,inputs)\n",
        "        return s_pred\n",
        "        \n",
        "    def count_params(self):\n",
        "        params = self.get_params(self.opt_state)\n",
        "        params_flat, _ = ravel_pytree(params)\n",
        "        print(\"The number of model parameters is:\",params_flat.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHw04xM1EBij"
      },
      "source": [
        "# Helper functions for prediction and error computation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55rjd6eA2vzp"
      },
      "source": [
        "We employ two helper functions, one for making predictions for the full resolution of the dataset and one for computing the error between the target and the predicted full resolution solution. \n",
        "\n",
        "In the predict function, we need to apply the harmonic feature expansion to the whole spatial grid for all realizations. This is handled by the `HarmonicFeatureExpansion` class presented previously. The input function samples are re-used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "tY-iL_L73c3Y"
      },
      "outputs": [],
      "source": [
        "def predict_function(U_in, Y_in, num_test=200, Nx=30, Ny=32,model=None,params= None, H=20, z= None, w=None):\n",
        "    print(\"Predicting the solution for the full resolution\")\n",
        "    y = np.expand_dims(Y_in,axis=0)\n",
        "    y = np.tile(y,(num_test,1,1))\n",
        "    u = jnp.asarray(scatteringTransform(U_in, training_batch_size=num_test))\n",
        "    pos_encodingy = HarmonicFeatureExpansionY(y,int(y.shape[1]*y.shape[2]), max_len = Nx*Ny, H=H)\n",
        "    y  = pos_encodingy.forward(y)\n",
        "    u_super_all = model.predict(params, (u,y, z, w))\n",
        "    return u_super_all\n",
        "\n",
        "\n",
        "def error_full_resolution(uCNN_super_all, s_all,tag='train', num_train=1000, P=128, Nx=32, Ny=32):\n",
        "    test_error_u = []\n",
        "    z = uCNN_super_all.reshape(num_train,Nx,Ny)\n",
        "    s = s_all.reshape(num_train,Nx,Ny)\n",
        "    for i in range(0,num_train):\n",
        "        test_error_u.append(norm(s[i,:,:]- z[i,:,:], 2)/norm(s[i,:,:], 2))\n",
        "    print(\"The average \"+tag+\" u error for the super resolution is %e, the standard deviation %e, the minimum error is %e and the maximum error is %e\"%(np.mean(test_error_u),np.std(test_error_u),np.min(test_error_u),np.max(test_error_u)))\n",
        "    absolute_error = np.abs(z-s)\n",
        "    return absolute_error, np.mean(test_error_u), test_error_u"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3fwHOMqEGsT"
      },
      "source": [
        "# Main part of the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZPIi87pEKgM"
      },
      "source": [
        "## Importing the training and testing datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "novHWOLC3oUI"
      },
      "source": [
        "We present the main part of the function that implements the DeepONet architecture. \n",
        "\n",
        "First we load the data and randomly choose output labels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cQ5jxFJ0B5hv"
      },
      "outputs": [],
      "source": [
        "TRAINING_ITERATIONS = 20000\n",
        "P = 128\n",
        "m = 1024\n",
        "num_train = 1000\n",
        "num_test  = 1000\n",
        "casenum_train = 2\n",
        "casenum_test  = 2\n",
        "training_batch_size = 100\n",
        "dx = 2\n",
        "du = 1\n",
        "dy = 2\n",
        "ds = 1\n",
        "n_hat  = 100\n",
        "l  = 100\n",
        "Nx = 32\n",
        "Ny = 32\n",
        "H = 6\n",
        "\n",
        "d = np.load(\"../Data/train_darcy_dataset.npz\")\n",
        "U_train   = d[\"U_train\"]\n",
        "Y_train   = d[\"Y_train\"]\n",
        "S_train   = d[\"s_train\"]\n",
        "\n",
        "d = np.load(\"../Data/test_darcy_dataset.npz\")\n",
        "U_test   = d[\"U_test\"]\n",
        "Y_test   = d[\"Y_test\"]\n",
        "S_test   = d[\"s_test\"]\n",
        "\n",
        "polypoints = 14\n",
        "lb = np.array([0.0, 0.0])\n",
        "ub = np.array([1.0, 1.0])\n",
        "\n",
        "# GLL nodes and weights in [-1,1]        \n",
        "z1, w1 = leggauss(polypoints)\n",
        "z2, w2 = leggauss(polypoints)\n",
        "\n",
        "# Rescale nodes to [lb,ub]\n",
        "x1 = 0.5*(ub[0] - lb[0])*(z1 + 1.0) + lb[0]\n",
        "x2 = 0.5*(ub[1] - lb[1])*(z2 + 1.0) + lb[1]\n",
        "\n",
        "# Determinant of Jacobian of mapping [lb,ub]-->[-1,1]^2\n",
        "jac_det = 0.5**2 * (ub[0]-lb[0]) * (ub[1]-lb[1])\n",
        "\n",
        "Z_1, Z_2 = np.meshgrid(z1,z2,indexing=\"ij\")\n",
        "\n",
        "Z = np.concatenate((Z_1.flatten()[:,None], Z_2.flatten()[:,None]), axis=-1)\n",
        "Z = np.tile(Z,(num_train,1,1))\n",
        "\n",
        "W = np.outer(w1, w2).flatten()[:,None]\n",
        "W = np.tile(W,(num_train,1,1))\n",
        "\n",
        "polypoints = polypoints**dy\n",
        "\n",
        "Y_train_in = Y_train\n",
        "Y_test_in = Y_test\n",
        "\n",
        "s_all_test = S_test[:num_test,:]\n",
        "s_all_train = S_train[:num_train,:]\n",
        "\n",
        "s_train = np.zeros((num_train,P,ds))\n",
        "y_train = np.zeros((num_train,P,dy))\n",
        "\n",
        "s_test = np.zeros((num_test,P,ds))\n",
        "y_test = np.zeros((num_test,P,dy))\n",
        "\n",
        "for i in range(0,num_train):\n",
        "    s_train[i,:,:], y_train[i,:,:] = output_construction(S_train[i,:], Y_train, Nx=Nx, Ny=Ny, P=P, ds=ds)\n",
        "\n",
        "for i in range(num_test):\n",
        "    s_test[i,:,:], y_test[i,:,:] = output_construction(S_test[i,:], Y_test, Nx=Nx, Ny=Ny, P=P, ds=ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIekGu1dEPs3"
      },
      "source": [
        "## Transforming them to JAX arrays"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEH1bCKbCES3"
      },
      "source": [
        "Then we transform the NumPy arrays into JAX DeviceArrays:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "YnJuim-ECPKM"
      },
      "outputs": [],
      "source": [
        "y_train_pos = y_train\n",
        "y_train_posT = y_test\n",
        "\n",
        "U_train = np.asarray(U_train)\n",
        "y_train = jnp.asarray(y_train)\n",
        "s_train = jnp.asarray(s_train)\n",
        "\n",
        "U_test = np.asarray(U_test)\n",
        "y_test = jnp.asarray(y_test)\n",
        "s_test = jnp.asarray(s_test)\n",
        "\n",
        "z = jnp.asarray(Z)\n",
        "w = jnp.asarray(W)\n",
        "\n",
        "U_train = np.reshape(U_train,(num_train,m,du))\n",
        "y_train = jnp.reshape(y_train,(num_train,P,dy))\n",
        "s_train = jnp.reshape(s_train,(num_train,P,ds))\n",
        "\n",
        "U_test = np.reshape(U_test,(num_test,m,du))\n",
        "y_test = jnp.reshape(y_test,(num_test,P,dy))\n",
        "s_test = jnp.reshape(s_test,(num_test,P,ds))\n",
        "\n",
        "z = jnp.reshape(z,(num_test,polypoints,dy))\n",
        "w = jnp.reshape(w,(num_test,polypoints,1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGvTRhBgETbc"
      },
      "source": [
        "## Applying the Harmonic Feature Expansion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QF4oXPQvCPx8"
      },
      "source": [
        "Apply the Harmonic Feature Expansion to both the output query points and the input function samples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "oFL_ELMO3ZSS"
      },
      "outputs": [],
      "source": [
        "pos_encodingy  = HarmonicFeatureExpansionY(y_train_pos,int(y_train_pos.shape[1]*y_train_pos.shape[2]), max_len = P, H=H)\n",
        "y_train  = pos_encodingy.forward(y_train)\n",
        "del pos_encodingy\n",
        "\n",
        "pos_encodingy  = HarmonicFeatureExpansionY(z,int(z.shape[1]*z.shape[2]), max_len = polypoints, H=H)\n",
        "z  = pos_encodingy.forward(z)\n",
        "del pos_encodingy\n",
        "\n",
        "pos_encodingyt = HarmonicFeatureExpansionY(y_train_posT,int(y_train_posT.shape[1]*y_train_posT.shape[2]), max_len = P, H=H)\n",
        "y_test   = pos_encodingyt.forward(y_test)\n",
        "del pos_encodingyt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Apply scattering transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "inputs_trainxu = jnp.asarray(scatteringTransform(U_train, training_batch_size=num_train))\n",
        "inputs_testxu  = jnp.asarray(scatteringTransform(U_test , training_batch_size=num_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo3_mY5MEaIw"
      },
      "source": [
        "## Handling mini-batches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KEGZFwiChqI"
      },
      "source": [
        "Pass the train and testing dataset to the DataGenerator class for creating mini-batches during training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "XHBQUASaChwA"
      },
      "outputs": [],
      "source": [
        "train_dataset = DataGenerator(inputs_trainxu, y_train, s_train, z, w, training_batch_size)\n",
        "train_dataset = iter(train_dataset)\n",
        "\n",
        "test_dataset = DataGenerator(inputs_testxu, y_test, s_test, z, w, training_batch_size)\n",
        "test_dataset = iter(test_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0Ftn3V-Eeae"
      },
      "source": [
        "## Choosing the model architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01J660acCxfP"
      },
      "source": [
        "Define the network architecture and the model class:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpguBt44Cxk0",
        "outputId": "5dfa707d-1a60-451f-98b1-8eba8d301e4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of model parameters is: 149102\n"
          ]
        }
      ],
      "source": [
        "q_layers = [dy+H*dy, 100, 100, l]\n",
        "v_layers = [768*du, 100, 100, ds*n_hat]\n",
        "g_layers = [l, 100, 100, ds*n_hat]\n",
        "\n",
        "# Define model\n",
        "model = LOCA(q_layers, g_layers, v_layers, m=m, P=P, jac_det=jac_det)\n",
        "\n",
        "model.count_params()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTZR_IVhEhdN"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKLuCoBqC0nY"
      },
      "source": [
        "Train the model and compute the wall-clock time needed for training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xK42ZwV6C0te",
        "outputId": "a28e73e3-a94b-421b-ffe1-f52b5e957bc9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20000/20000 [01:06<00:00, 302.85it/s, Training loss=1.9843934e-05, Testing loss=3.766751e-05, Test error=0.010893683, Train error=0.007880603]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The training wall-clock time is seconds is equal to 66.042935 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "start_time = timeit.default_timer()\n",
        "model.train(train_dataset, test_dataset, nIter=TRAINING_ITERATIONS)\n",
        "elapsed = timeit.default_timer() - start_time\n",
        "print(\"The training wall-clock time is seconds is equal to %f seconds\"%elapsed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxqTTj50EjP5"
      },
      "source": [
        "## Making predictions and computing the error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WkSwg-eC3zL"
      },
      "source": [
        "Use the model parameters to make predictions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-YXCtmfC34R",
        "outputId": "f421d96b-91e4-455e-e2c8-3e9e17683a62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting the solution for the full resolution\n",
            "Predicting the solution for the full resolution\n",
            "The average test u error for the super resolution is 6.654071e-03, the standard deviation 2.036762e-03, the minimum error is 3.092691e-03 and the maximum error is 1.813675e-02\n",
            "The average train u error for the super resolution is 4.552601e-03, the standard deviation 8.058764e-04, the minimum error is 2.746602e-03 and the maximum error is 8.351138e-03\n"
          ]
        }
      ],
      "source": [
        "params = model.get_params(model.opt_state)\n",
        "\n",
        "u_super_all_train  = predict_function(U_train, Y_train_in, model=model,Nx=Nx,Ny=Ny, params=params, H=H, z=z, w=w, num_test=num_train)\n",
        "u_super_all_test   = predict_function(U_test,  Y_test_in, model=model, Nx=Nx,Ny=Ny, params=params, H=H, z=z, w=w, num_test=num_test)\n",
        "\n",
        "absolute_error_test, mean_test_error, test_error     = error_full_resolution(u_super_all_test,  s_all_test,  tag='test', P=P, Nx=Nx, Ny=Ny, num_train=num_train)\n",
        "absolute_error_train, mean_train_error, train_error  = error_full_resolution(u_super_all_train, s_all_train, tag='train',P=P, Nx=Nx, Ny=Ny, num_train=num_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTP3ghRaIUMM"
      },
      "source": [
        "Save the model parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "LO_Mc6bJMVIA"
      },
      "outputs": [],
      "source": [
        "# Save trained model parameters\n",
        "saveParameters = True\n",
        "if saveParameters:\n",
        "    opt_params_flat, _ = ravel_pytree(params)\n",
        "    np.save(\"LOCA_parameters.npy\", opt_params_flat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## End of tutorial"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "DeepONets.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 ('pythonEnv')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "c0810597f4cdfad156af4c167b1913944419a16f12f4d923a45d088e15a92068"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
